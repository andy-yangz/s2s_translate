{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence to Sequence translation practice\n",
    "\n",
    "What I will do will like below.\n",
    "1. Build a baseline translation system.\n",
    "    1. One-directional RNN as encoder and decoder.\n",
    "    2. Have Attention architecture.\n",
    "2. Using word_embdding as input.\n",
    "3. Using bi-directional RNN\n",
    "4. Try more architecture.  \n",
    "\n",
    "About the language, at first try to reimplement system using German to English.  \n",
    "Then try to change it to Chinese to English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "- [ ] Establish a language class, it has word2index, index2word, and wordsdict.\n",
    "- [ ] Split corpus into language pairs.\n",
    "- [ ] Encode function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import cell\n",
    "import re\n",
    "import unicodedata\n",
    "import string\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    \"\"\"Language class. Can index words for input sentences.\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2ind = {'SOS':0, 'EOS':1}\n",
    "        self.word2cnt = {}\n",
    "        self.ind2word = {0:'SOS', 1:'EOS'}\n",
    "        self.nwords = 2\n",
    "    \n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split():\n",
    "            self.index_word(word.lower())\n",
    "    \n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2ind:\n",
    "            self.word2ind[word] = self.nwords\n",
    "            self.word2cnt[word] = 1\n",
    "            self.ind2word[self.nwords] = word\n",
    "            self.nwords += 1\n",
    "        else:\n",
    "            self.word2cnt[word] += 1\n",
    "            \n",
    "    def __str__(self):\n",
    "        return 'This is %s, it has %d words' % (self.name, self.nwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and decoding language\n",
    "First write function to decode and process the punctuation.  \n",
    "*How to normalize Chinese?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unicode2ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = unicode2ascii(s.lower().strip())\n",
    "    s = re.sub(r'([.!?])', r' \\1', s)\n",
    "    s = re.sub(r'[^a-zA-Z0-9.!?\\t]', r' ', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_langs(path, lang1_n, lang2_n):\n",
    "    lang1 = Lang(lang1_n)\n",
    "    lang2 = Lang(lang2_n)\n",
    "    data = open(os.path.join(path,'%s-%s.txt'%(lang1_n, lang2_n)))\n",
    "    pairs = []\n",
    "    \n",
    "    for line in data:\n",
    "        pair = normalize_string(line).strip().split('\\t')\n",
    "        pairs.append(pair)\n",
    "    return lang1, lang2, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "\n",
    "good_prefixes = (\n",
    "    \"i\",\n",
    "    \"he\", \n",
    "    \"she\", \n",
    "    \"you\", \n",
    "    \"they\",\n",
    "    \"we\"\n",
    ")\n",
    "\n",
    "def filter(p):\n",
    "    return(len(p[0]) < MAX_LENGTH and p[0].startswith(good_prefixes))\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return[pair for pair in pairs if filter(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path, lang1_name, lang2_name):\n",
    "    input_lang, output_lang, pairs = read_langs(path, lang1_name, lang2_name)\n",
    "    print(\"Read %d sentence pairs\" % len(pairs))\n",
    "    \n",
    "#     print(pairs[0:100])\n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimming to %d pairs.\" % len(pairs))\n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "    \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 152557 sentence pairs\n",
      "Trimming to 7388 pairs.\n",
      "Indexing words...\n"
     ]
    }
   ],
   "source": [
    "path = '/home/andy/data/lang_pairs/'\n",
    "lang1_name = 'eng'\n",
    "lang2_name = 'deu'\n",
    "input_lang, output_lang, pairs = prepare_data(path, lang1_name, lang2_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turning data to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_sentence(sentence, lang):\n",
    "    return [lang.word2ind[word] for word in sentence.strip().split()]\n",
    "\n",
    "def variable_sentence(sentence, lang):\n",
    "    indexs = index_sentence(sentence, lang)\n",
    "    indexs = indexs + [EOS_token]\n",
    "    var = Variable(torch.LongTensor(indexs).view(-1, 1)).cuda()\n",
    "    return var\n",
    "\n",
    "def variable_pair(pair):\n",
    "    input_var = variable_sentence(pair[0], input_lang)\n",
    "    output_var = variable_sentence(pair[1], output_lang)\n",
    "    return (input_var, output_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "We can use normal RNN layer to input input pair.\n",
    "Get the final state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "    \n",
    "    def forward(self, words_input, hidden):\n",
    "        seq_len = len(words_input)\n",
    "        embeded = self.embedding(words_input).view(seq_len, 1, -1)\n",
    "        output, hidden = self.gru(embeded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def ini_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size)).cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Decoder\n",
    "$$\n",
    "p(y_i \\mid \\{y_1,...,y_{i-1}\\}, x) = g(y_{i-1}, s_i, c_i)  \n",
    "$$\n",
    "$$\n",
    "s_i = f(s_{i-1}, y_{i-1}, c_i)  \n",
    "$$\n",
    "$$\n",
    "c_i = \\sum_{j=1}^{T_x}a_{ij}h_i  \n",
    "$$\n",
    "$$\n",
    "a_{ij} = \\dfrac{exp(e_{ij})}{\\sum_{k=1}^Texp(e_{ik})}\n",
    "$$\n",
    "$$\n",
    "e_{ij} = a(s_{i-1}, h_{j})\n",
    "$$\n",
    "\n",
    "The general form of the attention calculation relies on the target (decoder) side hidden state and corresponding source (encoder) side state, normalized over all states to get values summing to 1:\n",
    "\n",
    "$$\n",
    "a_t(s) = align(h_t, \\bar h_s)  = \\dfrac{exp(score(h_t, \\bar h_s))}{\\sum_{s'} exp(score(h_t, \\bar h_{s'}))}\n",
    "$$\n",
    "\n",
    "The specific \"score\" function that compares two states is either *dot*, a simple dot product between the states; *general*, a a dot product between the decoder hidden state and a linear transform of the encoder state; or *concat*, a dot product between a new parameter $v_a$ and a linear transform of the states concatenated together.\n",
    "\n",
    "$$\n",
    "score(h_t, \\bar h_s) =\n",
    "\\begin{cases}\n",
    "h_t ^\\top \\bar h_s & dot \\\\\n",
    "h_t ^\\top \\textbf{W}_a \\bar h_s & general \\\\\n",
    "v_a ^\\top \\textbf{W}_a [ h_t ; \\bar h_s ] & concat\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The modular definition of these scoring functions gives us an opportunity to build specific attention module that can switch between the different score methods. The input to this module is always the hidden state (of the decoder RNN) and set of encoder outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if method == 'general':\n",
    "            self.attn = nn.Linear(hidden_size, hidden_size)\n",
    "        elif method == 'concat':\n",
    "            self.attn = nn.Linear(hidden_size*2, hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = len(encoder_outputs)\n",
    "        attn_energies = Variable(torch.zeros(seq_len)).cuda()\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[i] = self.score(hidden, encoder_outputs[i])\n",
    "        return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        if self.method == 'dot':\n",
    "            return hidden.squeeze().dot(encoder_output.squeeze())\n",
    "        if self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.squeeze().dot(energy.squeeze())\n",
    "            return  energy\n",
    "        if self.method == 'concat':\n",
    "            energy = self.attn(torch.cat(hidden, encoder_output), 1)\n",
    "            energy = self.other.dot(energy.squeeze())\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_mode, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # Parameters\n",
    "        self.attn_mode = attn_mode\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "        #Attn mode\n",
    "        if attn_mode != None:\n",
    "            self.attn = Attn(attn_mode, hidden_size)\n",
    "            \n",
    "    def forward(self, word_input, last_hidden, last_context, encoder_outputs):\n",
    "        word_embeded = self.embedding(word_input).view(1, 1, -1)\n",
    "        \n",
    "        rnn_input = torch.cat((word_embeded, last_context.unsqueeze(0)), 2)\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \n",
    "        attn_weight = self.attn(rnn_output.squeeze(0), encoder_outputs)\n",
    "        context = attn_weight.bmm(encoder_outputs.transpose(0, 1))\n",
    "        \n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\n",
    "        return output, context, hidden, attn_weight\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN (\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(10, 10, num_layers=2)\n",
      ")\n",
      "AttnDecoderRNN (\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(20, 10, num_layers=2, dropout=0.1)\n",
      "  (out): Linear (20 -> 10)\n",
      "  (attn): Attn (\n",
      "    (attn): Linear (10 -> 10)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 10]) torch.Size([2, 1, 10]) torch.Size([1, 1, 3])\n",
      "torch.Size([1, 10]) torch.Size([2, 1, 10]) torch.Size([1, 1, 3])\n",
      "torch.Size([1, 10]) torch.Size([2, 1, 10]) torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "encoder_test = EncoderRNN(10, 10, 2).cuda()\n",
    "decoder_test = AttnDecoderRNN('general', 10, 10, 2).cuda()\n",
    "print(encoder_test)\n",
    "print(decoder_test)\n",
    "\n",
    "encoder_hidden = encoder_test.ini_hidden()\n",
    "word_input =  Variable(torch.LongTensor([1, 2, 3])).cuda()\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "decoder_attns = torch.zeros(1, 3, 3)\n",
    "decoder_hidden = encoder_hidden\n",
    "decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size)).cuda()\n",
    "\n",
    "for i in range(3):\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attn = decoder_test(word_input[i], decoder_hidden,\n",
    "                                                                               decoder_context, encoder_outputs)\n",
    "    print(decoder_output.size(), decoder_hidden.size(), decoder_attn.size())\n",
    "    decoder_attns[0, i] = decoder_attn.squeeze(0).cpu().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "The process:\n",
    "1. First, run sentence word by word, and last get the outputs and last hidden state.\n",
    "2. Feed hidden state and first input word SOS to decoder input and context.init.\n",
    "3. And get output, hidden state. Do cycle.\n",
    "4. When training, use teacher forcing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_force_ratio = 0.5\n",
    "clip = 5\n",
    "\n",
    "def training(input_var, target_var, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    #Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    #Get length\n",
    "    input_len = input_var.size()[0]\n",
    "    target_len = target_var.size()[0]\n",
    "    \n",
    "    #Run words through encoder\n",
    "    encoder_hidden = encoder.ini_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_var, encoder_hidden)\n",
    "    \n",
    "    #Then go to decoder, prepare input, context, hidden first\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]])).cuda()\n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size)).cuda()\n",
    "    \n",
    "    #Training decoder, use teacher enforce\n",
    "    is_teacher_enforce = random.random() < teacher_force_ratio\n",
    "    if is_teacher_enforce:\n",
    "        for i in range(target_len):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_atten = decoder(decoder_input,\n",
    "                                                                                    decoder_hidden,\n",
    "                                                                                    decoder_context,\n",
    "                                                                                    encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_var[i])\n",
    "            decoder_input = target_var[i]\n",
    "    else:\n",
    "        for i in range(target_len):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_atten = decoder(decoder_input,\n",
    "                                                                                    decoder_hidden,\n",
    "                                                                                    decoder_context,\n",
    "                                                                                    encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_var[i])\n",
    "            \n",
    "            _, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor(ni)).cuda()\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "    \n",
    "    #Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Time helper\n",
    "def as_min(s):\n",
    "    m = s//60\n",
    "    s = s % 60\n",
    "    return \"%dm %ds\" % (m,s)\n",
    "\n",
    "def since_time(since, percent):\n",
    "    s = time.time()\n",
    "    s = s - since\n",
    "    es = s / percent\n",
    "    rs = es - s\n",
    "    return \"%s - (%s)\" % (as_min(s), as_min(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyperparameter, initial model, optimizor, and loss function\n",
    "attn_mode = \"general\"\n",
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout = 0.05\n",
    "\n",
    "#initial model\n",
    "encoder = EncoderRNN(input_lang.nwords, hidden_size, n_layers).cuda()\n",
    "decoder = AttnDecoderRNN(attn_mode, hidden_size, output_lang.nwords, n_layers, dropout).cuda()\n",
    "\n",
    "#optimizor and learning_rate\n",
    "learning_rate = 1e-4\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting and data\n",
    "n_epochs = 50000\n",
    "plot_every = 300\n",
    "print_every = 1000\n",
    "\n",
    "#history storage\n",
    "plot_losses = []\n",
    "plot_loss_total = 0\n",
    "print_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /home/andy/tools/pytorch/torch/lib/THC/generic/THCTensorCopy.c:18",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bb9c1c18f523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Get data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#Running traning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b47f7846d06d>\u001b[0m in \u001b[0;36mvariable_pair\u001b[0;34m(pair)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvariable_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0minput_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0moutput_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b47f7846d06d>\u001b[0m in \u001b[0;36mvariable_sentence\u001b[0;34m(sentence, lang)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mindexs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mindexs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEOS_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id, async)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device_id, async)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /home/andy/tools/pytorch/torch/lib/THC/generic/THCTensorCopy.c:18"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # Get data\n",
    "    input_var, output_var = variable_pair(random.choice(pairs))\n",
    "    \n",
    "    #Running traning\n",
    "    loss = training(input_var, output_var, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "#     print(loss)\n",
    "    #keep track of loss\n",
    "    plot_loss_total += loss\n",
    "    print_loss_total += loss\n",
    "    \n",
    "    #keep plot\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_losses.append(plot_loss_total/plot_every)\n",
    "        plot_loss_total = 0\n",
    "    \n",
    "    #print states\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_ave = print_loss_total / print_every\n",
    "        since = time.time()\n",
    "        print(\"%s (%d %d%%) %.4f\" % (since_time(since, epoch/n_epochs), epoch, epoch/n_epochs, print_loss_ave))\n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
